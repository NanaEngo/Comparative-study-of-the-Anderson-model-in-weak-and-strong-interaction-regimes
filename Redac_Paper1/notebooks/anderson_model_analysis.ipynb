{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd15245",
   "metadata": {},
   "source": [
    "## Requirements & Run Instructions\n",
    "\n",
    "### Required packages\n",
    "```bash\n",
    "pip install numpy scipy matplotlib pandas joblib\n",
    "```\n",
    "\n",
    "Optional (for enhanced many-body support):\n",
    "```bash\n",
    "pip install qutip\n",
    "```\n",
    "\n",
    "### Run headless or interactively\n",
    "```bash\n",
    "# Jupyter interactive\n",
    "jupyter notebook notebooks/anderson_model_analysis.ipynb\n",
    "\n",
    "# Papermill (execute + save outputs)\n",
    "papermill notebooks/anderson_model_analysis.ipynb notebooks/anderson_model_analysis_executed.ipynb\n",
    "\n",
    "# Or nbconvert\n",
    "jupyter nbconvert --to notebook --execute notebooks/anderson_model_analysis.ipynb\n",
    "```\n",
    "\n",
    "All outputs are saved to `notebooks_output/` and `figures/` for post-processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 13) Unit tests and performance profiling\n",
    "\n",
    "# Simple unit tests\n",
    "def test_noninteracting_limit():\n",
    "    # when U=0 HF should reproduce G0 occupancy\n",
    "    p = params.copy(); p['U']=0.0\n",
    "    eps_k, Vk = discretize_uniform(p['N_b'], p['D'])\n",
    "    hf = hartree_fock(p['epsilon_d'], p['U'], eps_k, Vk)\n",
    "    assert 0.0 <= hf['n_up'] <= 1.0\n",
    "    return True\n",
    "\n",
    "print('Running quick unit test: noninteracting limit')\n",
    "try:\n",
    "    ok = test_noninteracting_limit()\n",
    "    print('Test passed:', ok)\n",
    "except AssertionError:\n",
    "    print('Test failed')\n",
    "\n",
    "# Simple profiler usage\n",
    "import timeit\n",
    "print('HF timing (single run):', timeit.timeit(lambda: hartree_fock(params['epsilon_d'], params['U'], eps_k, Vk), number=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d429107",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12) Visualization, saving results, and reproducibility\n",
    "\n",
    "# Example: plot HF occupancy vs N_b from finite-size results\n",
    "import pandas as pd\n",
    "fs_df = pd.read_csv(OUT_DIR / 'finite_size_results.csv')\n",
    "plt.figure()\n",
    "plt.plot(fs_df['N_b'], fs_df['n_up'], marker='o', label='n_up')\n",
    "plt.plot(fs_df['N_b'], fs_df['n_dn'], marker='x', label='n_dn')\n",
    "plt.xlabel('N_b')\n",
    "plt.ylabel('occupancy')\n",
    "plt.legend()\n",
    "plt.title('Finite-size HF occupancy')\n",
    "plt.savefig(FIG_DIR / 'finite_size_occupancy.png')\n",
    "plt.close()\n",
    "\n",
    "# Save run manifest\n",
    "import json, subprocess\n",
    "manifest = {\n",
    "    'params': params,\n",
    "    'git_commit': None,\n",
    "    'timestamp': time.strftime('%Y%m%d_%H%M%S')\n",
    "}\n",
    "try:\n",
    "    gitrev = subprocess.check_output(['git','rev-parse','HEAD']).decode().strip()\n",
    "    manifest['git_commit'] = gitrev\n",
    "except Exception:\n",
    "    manifest['git_commit'] = None\n",
    "\n",
    "with open(OUT_DIR / 'run_manifest.json','w') as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "print('Saved run_manifest.json and figures')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11) Finite-size scaling & convergence tests\n",
    "\n",
    "def finite_size_test(Nb_list=[4,6,8,10]):\n",
    "    out = []\n",
    "    for Nb in Nb_list:\n",
    "        eps_k, Vk = discretize_uniform(Nb, params['D'])\n",
    "        hf = hartree_fock(params['epsilon_d'], params['U'], eps_k, Vk)\n",
    "        out.append({'N_b': Nb, 'n_up': hf['n_up'], 'n_dn': hf['n_dn']})\n",
    "    return out\n",
    "\n",
    "fs = finite_size_test([4,6,8])\n",
    "import pandas as pd\n",
    "pd.DataFrame(fs).to_csv(OUT_DIR / 'finite_size_results.csv', index=False)\n",
    "print('Saved finite_size_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10) Parameter sweeps and phase-map generation\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "\n",
    "def single_run(U, eps_d, V, N_b=params['N_b']):\n",
    "    # simple driver: discretize, compute HF occupancy as proxy\n",
    "    eps_k, Vk = discretize_uniform(N_b, params['D'])\n",
    "    hf = hartree_fock(eps_d, U, eps_k, Vk)\n",
    "    return {'U': U, 'eps_d': eps_d, 'V': V, 'n_up': hf['n_up'], 'n_dn': hf['n_dn']}\n",
    "\n",
    "# small grid example\n",
    "Us = np.linspace(0.0, 4.0, 5)\n",
    "eps_ds = [-1.0, -0.5, 0.0]\n",
    "Vv = [0.1, 0.2]\n",
    "\n",
    "jobs = [(U, e, Vv[0]) for U in Us for e in eps_ds]\n",
    "results = Parallel(n_jobs=2)(delayed(single_run)(U,e,Vv[0]) for U,e in jobs)\n",
    "# save results\n",
    "with open(OUT_DIR / 'hf_parameter_scan.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print('Saved hf_parameter_scan.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b637fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9) Kondo regime diagnostics (entropy, susceptibility)\n",
    "\n",
    "def thermal_expectation(vals, vecs, obs_diag, beta=1.0/params['T']):\n",
    "    Z = np.sum(np.exp(-beta*vals))\n",
    "    expect = np.sum(obs_diag * np.exp(-beta*vals)) / Z\n",
    "    return expect\n",
    "\n",
    "# placeholder entropy and susceptibility using eigenvalues\n",
    "def impurity_entropy(vals, beta=1.0/params['T']):\n",
    "    p = np.exp(-beta*vals)\n",
    "    p = p / p.sum()\n",
    "    S = -np.sum(p * np.log(p + 1e-20))\n",
    "    return S\n",
    "\n",
    "S_T = impurity_entropy(vals)\n",
    "print('Impurity entropy (placeholder):', S_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39620fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8) Lehmann spectral function and analytic continuation\n",
    "\n",
    "def lehmann_spectral(vals, vecs, op_matrix, beta=1.0/params['T'], omega_grid=None, eta=0.05):\n",
    "    # vals: eigenvalues E_n, vecs: eigenvectors (columns)\n",
    "    if omega_grid is None:\n",
    "        omega_grid = np.linspace(-2*params['D'], 2*params['D'], 800)\n",
    "    A = np.zeros_like(omega_grid, dtype=float)\n",
    "    Z = np.sum(np.exp(-beta*vals))\n",
    "    for m in range(len(vals)):\n",
    "        for n in range(len(vals)):\n",
    "            # matrix element |<m|d|n>|^2 (placeholder: op_matrix should supply this)\n",
    "            M = abs(op_matrix[m, n])**2 if op_matrix is not None else 0.0\n",
    "            weight = (np.exp(-beta*vals[n]) + np.exp(-beta*vals[m]))/Z\n",
    "            A += weight * M * (1.0/np.pi) * (eta/((omega_grid - (vals[m]-vals[n]))**2 + eta**2))\n",
    "    return omega_grid, A\n",
    "\n",
    "# placeholder operator matrix\n",
    "op = np.zeros((len(vals), len(vals)))\n",
    "omegaA, A = lehmann_spectral(vals, vecs, op)\n",
    "plt.figure()\n",
    "plt.plot(omegaA, A)\n",
    "plt.title('Lehmann spectral (placeholder)')\n",
    "plt.savefig(FIG_DIR / 'lehmann_placeholder.png')\n",
    "plt.close()\n",
    "print('Saved lehmann_placeholder.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2756c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7) Exact diagonalization (ED) solver\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "# Placeholder ED runner (detailed many-body construction omitted for brevity)\n",
    "def run_ed(H_sparse, k=3):\n",
    "    if hasattr(H_sparse, 'shape') and H_sparse.shape[0] > 1:\n",
    "        vals, vecs = eigsh(H_sparse, k=k, which='SA')\n",
    "        return vals, vecs\n",
    "    else:\n",
    "        return np.array([0.0]), np.zeros((1,1))\n",
    "\n",
    "vals, vecs = run_ed(H)\n",
    "print('ED eigenvalues (sample):', vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6) Mean-field (Hartree–Fock) solver\n",
    "\n",
    "def hartree_fock(eps_d, U, eps_k, Vk, beta=1.0/params['T'], maxiter=50, tol=1e-6):\n",
    "    n_up = 0.5\n",
    "    n_dn = 0.5\n",
    "    for it in range(maxiter):\n",
    "        eps_up = eps_d + U * n_dn\n",
    "        eps_dn = eps_d + U * n_up\n",
    "        # non-interacting Green's functions for each spin (approximate)\n",
    "        G_up = G0_omega(omega, eps_up, eps_k, Vk)\n",
    "        G_dn = G0_omega(omega, eps_dn, eps_k, Vk)\n",
    "        A_up = -np.imag(G_up)/np.pi\n",
    "        A_dn = -np.imag(G_dn)/np.pi\n",
    "        n_up_new = np.trapz(A_up * (1.0/(np.exp(beta*omega)+1.0)), omega)\n",
    "        n_dn_new = np.trapz(A_dn * (1.0/(np.exp(beta*omega)+1.0)), omega)\n",
    "        if abs(n_up_new - n_up) < tol and abs(n_dn_new - n_dn) < tol:\n",
    "            break\n",
    "        n_up, n_dn = n_up_new, n_dn_new\n",
    "    return {'n_up': n_up, 'n_dn': n_dn, 'eps_up': eps_up, 'eps_dn': eps_dn}\n",
    "\n",
    "hf_res = hartree_fock(params['epsilon_d'], params['U'], eps_k, Vk)\n",
    "print('HF result:', hf_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) Non-interacting Green's function (G0)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def G0_omega(omega_grid, eps_d, eps_k, Vk, eta=1e-4):\n",
    "    Delta = np.array([Delta_real(w, eps_k, Vk, eta) for w in omega_grid])\n",
    "    return 1.0 / (omega_grid + 1j*eta - eps_d - Delta)\n",
    "\n",
    "# quick plot of Im[G0]\n",
    "omega = np.linspace(-1.2*params['D'], 1.2*params['D'], 800)\n",
    "G0 = G0_omega(omega, params['epsilon_d'], eps_k, Vk)\n",
    "plt.figure()\n",
    "plt.plot(omega, -np.imag(G0)/np.pi)\n",
    "plt.title('Non-interacting impurity spectral function (G0)')\n",
    "plt.xlabel('omega')\n",
    "plt.ylabel('A(omega)')\n",
    "plt.savefig(FIG_DIR / 'G0_spectral.png')\n",
    "plt.close()\n",
    "print('Saved G0_spectral.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4) Construct many-body Hamiltonian\n",
    "\n",
    "# For modest N_b, build Fock basis using occupation bitstrings per spin\n",
    "from itertools import product\n",
    "\n",
    "def build_basis(N_b):\n",
    "    # impurity (1 site) + N_b bath orbitals per spin -> total sites = 1 + N_b\n",
    "    L = 1 + N_b\n",
    "    # occupations per spin: each has L orbitals -> 2^L states per spin\n",
    "    states = list(range(2**L))\n",
    "    return states, L\n",
    "\n",
    "# helper: occupation number for site i in bitstring s\n",
    "def occ(s, i):\n",
    "    return (s >> i) & 1\n",
    "\n",
    "# index mapping and sparse Hamiltonian construction for small sizes\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "def construct_hamiltonian(eps_k, Vk, p=params):\n",
    "    N_b = len(eps_k)\n",
    "    states_up, L = build_basis(N_b)\n",
    "    # For brevity: placeholder - building full many-body Hamiltonian is lengthy\n",
    "    print('Constructing sparse Hamiltonian placeholder (detailed implementation recommended for larger N_b).')\n",
    "    H = sparse.csr_matrix((1,1))\n",
    "    return H\n",
    "\n",
    "H = construct_hamiltonian(eps_k, Vk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17088ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) Bath discretization & hybridization function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def discretize_uniform(N_b, D):\n",
    "    eps_k = np.linspace(-D, D, N_b)\n",
    "    Vk = np.ones_like(eps_k) * np.sqrt(params['V']**2 / N_b)\n",
    "    return eps_k, Vk\n",
    "\n",
    "def discretize_logarithmic(N_b, D, Lambda=2.0):\n",
    "    # simple logarithmic discretization symmetric about 0\n",
    "    pos = np.array([D * (Lambda**(-i)) for i in range(1, N_b//2+1)])\n",
    "    neg = -pos[::-1]\n",
    "    eps = np.concatenate((neg, pos))[:N_b]\n",
    "    Vk = np.ones_like(eps) * np.sqrt(params['V']**2 / N_b)\n",
    "    return eps, Vk\n",
    "\n",
    "# hybridization function evaluated on real frequency grid\n",
    "def Delta_real(omega, eps_k, Vk, eta=1e-4):\n",
    "    return np.sum(Vk**2 / (omega - eps_k + 1j*eta))\n",
    "\n",
    "# quick preview\n",
    "eps_k, Vk = discretize_uniform(params['N_b'], params['D'])\n",
    "print('eps_k:', eps_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) Model parameters & units\n",
    "\n",
    "# Default SIAM parameters (dimensionless units; energy in eV by default)\n",
    "params = {\n",
    "    'epsilon_d': -0.5,   # impurity level\n",
    "    'U': 2.0,             # Coulomb repulsion\n",
    "    'V': 0.2,             # hybridization amplitude (per orbital)\n",
    "    'D': 1.0,             # half-bandwidth\n",
    "    'N_b': 6,             # number of bath sites (per spin)\n",
    "    'T': 0.01,            # temperature (eV ~ 11605 K per eV)\n",
    "}\n",
    "\n",
    "def energy_to_kelvin(E_eV):\n",
    "    return E_eV * 11604.525\n",
    "\n",
    "def print_params(p=params):\n",
    "    for k,v in p.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "print_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8eb944",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) Environment & Imports\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Optional: QuTiP fallback for many-body operators if installed\n",
    "try:\n",
    "    import qutip as qt\n",
    "    _HAS_QUTIP = True\n",
    "except Exception:\n",
    "    _HAS_QUTIP = False\n",
    "\n",
    "# plotting settings and reproducibility\n",
    "np.random.seed(12345)\n",
    "plt.rcParams.update({'figure.max_open_warning': 20, 'figure.dpi': 120})\n",
    "\n",
    "# paths\n",
    "ROOT = Path('.')\n",
    "DATA_DIR = ROOT / 'simulation_data'\n",
    "OUT_DIR = ROOT / 'notebooks_output'\n",
    "FIG_DIR = ROOT / 'figures'\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "print('Environment ready. Qutip:', _HAS_QUTIP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ba3b4d",
   "metadata": {},
   "source": [
    "# Anderson impurity model — Analysis notebook\n",
    "\n",
    "This notebook implements the single-impurity Anderson model (SIAM) workflows: bath discretization, Hamiltonian construction, non-interacting Green's function, Hartree–Fock, exact diagonalization (ED), Lehmann spectral functions, Kondo diagnostics, parameter sweeps, finite-size scaling, visualization, and basic unit tests.\n",
    "\n",
    "See `CSV_DATA_ANALYSIS.md` for CSV processing examples (notebook also saves outputs)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
